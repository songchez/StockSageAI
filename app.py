from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph import StateGraph, END,START
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.runnables import RunnableConfig
from langchain_teddynote import logging
import streamlit as st
from dotenv import load_dotenv
from tools.search_tools import search_news, search_DDG
from langgraph.prebuilt import ToolNode, tools_condition
from utils.visualize import visualize_graph_in_streamlit



# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LangSmith ë¡œê¹… ì„¤ì •
logging.langsmith("pr-dear-ratepayer-64")

# Toolsì´ˆê¸°í™”
tools = [search_news, search_DDG]
tool_node = ToolNode(tools)

# LangGraphë¥¼ ìœ„í•œ ìƒíƒœ íƒ€ì… ì •ì˜
class State(TypedDict):
    messages: Annotated[list, add_messages]

# ì±„íŒ… ë…¸ë“œ ì •ì˜
def chatbot(state: State):
    # Gemini ëª¨ë¸ ì‚¬ìš©
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-pro-exp-03-25",
        temperature=0.1,
        max_output_tokens=2048
    ).bind_tools(tools)

    # ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
    return {
        "messages": [llm.invoke(state["messages"])]
    }



memory = MemorySaver()
workflow = StateGraph(State)
# ë…¸ë“œ ì¶”ê°€
workflow.add_node("agent", chatbot)
workflow.add_node("tools", tool_node)

# ì—£ì§€ ì¶”ê°€
workflow.add_edge(START, "agent")
workflow.add_conditional_edges("agent", tools_condition)

# ë„êµ¬ ë…¸ë“œì—ì„œ ì—ì´ì „íŠ¸ ë…¸ë“œë¡œ ìˆœí™˜ ì—°ê²°
workflow.add_edge("tools", "agent")

workflow.add_edge("agent", END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
graph = workflow.compile(checkpointer=memory)




config = RunnableConfig(
    recursion_limit=10,  # ìµœëŒ€ 10ê°œì˜ ë…¸ë“œê¹Œì§€ ë°©ë¬¸. ê·¸ ì´ìƒì€ RecursionError ë°œìƒ
    configurable={"thread_id": "1"},  # ìŠ¤ë ˆë“œ ID ì„¤ì •
)

# Streamlit UI


# ì‚¬ì´ë“œë°”ì— ê·¸ë˜í”„ ì‹œê°í™” ì¶”ê°€
with st.sidebar:
    st.title("ğŸ”º ì£¼ì‹íˆ¬ìë¥¼ ìœ„í•œ LangGraph ì±—ë´‡")
    st.header("Structure of LangGraph")
    visualize_graph_in_streamlit(graph, xray=False)


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.title("StockSageAI")
    st.subheader("ì£¼ì‹íˆ¬ìë¥¼ ìœ„í•œ ì±—ë´‡ì…ë‹ˆë‹¤. AIì—ê²Œ íˆ¬ìê²°ì •ì— ë„ì›€ë°›ì„ ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë¶„ì„ì„ ìš”ì²­í•´ë³´ì„¸ìš”!")
    
# # ìŠ¤ë ˆë“œ ID ê´€ë¦¬ (ì‚¬ìš©ìë³„ë¡œ ê³ ìœ í•œ ëŒ€í™” ìŠ¤ë ˆë“œ)
# if "thread_id" not in st.session_state:
#     import uuid
#     st.session_state.thread_id = str(uuid.uuid4())

# ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    if isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.write(message.content)
    else:
        with st.chat_message("assistant"):
            st.write(message.content)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.write(prompt)
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    st.session_state.messages.append(HumanMessage(content=prompt))

    # ì‘ë‹µ ì¤€ë¹„
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        FULL_RESPONSE = ""

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        with st.spinner("ìƒê° ì¤‘..."):
            for event in graph.stream(
                input={"messages": [("user", prompt)]},
                config=config,
                output_keys=["messages"]
            ):
                for key, value in event.items():
                    if value and "messages" in value:
                        # ìƒˆë¡œìš´ ë©”ì‹œì§€ ë‚´ìš© ì¶”ì¶œ
                        new_content = value["messages"][-1].content
                        if new_content and isinstance(new_content, str) and new_content != FULL_RESPONSE:
                            # ì—…ë°ì´íŠ¸ëœ ì „ì²´ ì‘ë‹µìœ¼ë¡œ ì„¤ì •
                            FULL_RESPONSE = new_content
                            # í™”ë©´ì— ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
                            message_placeholder.markdown(FULL_RESPONSE)
    
    # ê²°ê³¼ì—ì„œ AI ì‘ë‹µ ì¶”ì¶œ ë° í‘œì‹œ
    ai_message = AIMessage(content=FULL_RESPONSE)
    st.session_state.messages.append(ai_message)