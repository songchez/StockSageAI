from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END,START
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.runnables import RunnableConfig
from langchain_teddynote import logging
import streamlit as st
from dotenv import load_dotenv
from tools.search_tools import search_news, search_DDG
from langgraph.prebuilt import ToolNode, tools_condition

tools = [search_news, search_DDG]
tool_node = ToolNode(tools)


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LangSmith ë¡œê¹… ì„¤ì •
logging.langsmith("pr-dear-ratepayer-64")

# LangGraphë¥¼ ìœ„í•œ ìƒíƒœ íƒ€ì… ì •ì˜
class State(TypedDict):
    messages: Annotated[list, add_messages]

# ì±„íŒ… ë…¸ë“œ ì •ì˜
def chatbot(state: State):
    # Gemini ëª¨ë¸ ì‚¬ìš©
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-pro-exp-03-25",
        temperature=0.1,
        max_output_tokens=2048
    ).bind_tools(tools)

    # ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
    return {
        "messages": [llm.invoke(state["messages"])]
    }



memory = MemorySaver()
workflow = StateGraph(State)
# ë…¸ë“œ ì¶”ê°€
workflow.add_node("agent", chatbot)
workflow.add_node("tools", tool_node)

# ì—£ì§€ ì¶”ê°€
workflow.add_edge(START, "agent")
workflow.add_conditional_edges("agent", tools_condition)

# ë„êµ¬ ë…¸ë“œì—ì„œ ì—ì´ì „íŠ¸ ë…¸ë“œë¡œ ìˆœí™˜ ì—°ê²°
workflow.add_edge("tools", "agent")

workflow.add_edge("agent", END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
graph = workflow.compile(checkpointer=memory)

from utils.visualize import visualize_graph_in_streamlit



config = RunnableConfig(
    recursion_limit=10,  # ìµœëŒ€ 10ê°œì˜ ë…¸ë“œê¹Œì§€ ë°©ë¬¸. ê·¸ ì´ìƒì€ RecursionError ë°œìƒ
    configurable={"thread_id": "1"},  # ìŠ¤ë ˆë“œ ID ì„¤ì •
)

# Streamlit UI


# ì‚¬ì´ë“œë°”ì— ê·¸ë˜í”„ ì‹œê°í™” ì¶”ê°€
with st.sidebar:
    st.title("ğŸ¤– ê°„ë‹¨í•œ LangGraph ì±—ë´‡")
    st.header("ğŸ“Š LangGraph ì‹œê°í™”")
    xray_mode = st.checkbox("X-ray ëª¨ë“œ (ìƒì„¸ ì •ë³´ í‘œì‹œ)", value=False)
    st.write("ì±—ë´‡ ê·¸ë˜í”„ êµ¬ì¡°")
    visualize_graph_in_streamlit(graph, xray=xray_mode)


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.title("StockSageAI")
    st.subheader("ì£¼ì‹íˆ¬ìë¥¼ ìœ„í•œ ì±—ë´‡ì…ë‹ˆë‹¤. AIì—ê²Œ íˆ¬ìê²°ì •ì— ë„ì›€ë°›ì„ ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë¶„ì„ì„ ìš”ì²­í•´ë³´ì„¸ìš”!")
    
# # ìŠ¤ë ˆë“œ ID ê´€ë¦¬ (ì‚¬ìš©ìë³„ë¡œ ê³ ìœ í•œ ëŒ€í™” ìŠ¤ë ˆë“œ)
# if "thread_id" not in st.session_state:
#     import uuid
#     st.session_state.thread_id = str(uuid.uuid4())

# ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    if isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.write(message.content)
    else:
        with st.chat_message("assistant"):
            st.write(message.content)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.write(prompt)
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    st.session_state.messages.append(HumanMessage(content=prompt))

    # ê·¸ë˜í”„ ì‹¤í–‰
    with st.spinner("ìƒê° ì¤‘..."):
        result = graph.invoke({"messages": [("user", prompt)]}, config=config)
        
    
    # ê²°ê³¼ì—ì„œ AI ì‘ë‹µ ì¶”ì¶œ ë° í‘œì‹œ
    ai_message = result["messages"][-1]
    st.session_state.messages.append(ai_message)
    
    with st.chat_message("assistant"):
        st.write(ai_message.content)